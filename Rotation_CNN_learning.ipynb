{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rotation_CNN_learning",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phillevn/Rotation-and-CNN-for-MNIST-learning/blob/master/Rotation_CNN_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXwZDJKx0zLB",
        "colab_type": "text"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "097_gois0-h-",
        "colab_type": "text"
      },
      "source": [
        "## Convolution Neuron Network\n",
        "\n",
        "In this post we will discuss some advantages of image rotation learning for MNIST set. As we know that, Convolution Neuron Network show that it is very efficient to classify the handwriting numbers in MNIST set. With the epoch = 10, we have the accuracy upto 98% when we evaluate the x_test, y_test set. \n",
        "\n",
        "### An issue with the original dataset\n",
        "\n",
        "When we train the machine with the original dataset, it works beautifully. However, there is an issue with it. If we look closer to the dataset. The data set was almost processed to oriented in vertical way. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHNJQG983Kl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import datetime\n",
        "from datetime import date\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from plotly import __version__\n",
        "%matplotlib inline\n",
        "\n",
        "import plotly.offline as pyo\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import iplot\n",
        "\n",
        "import cufflinks as cf\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2IYHRBm3n1l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f8c812a7-2888-4b44-965b-8854f514ad33"
      },
      "source": [
        "mnist = keras.datasets.mnist\n",
        "(X1_train_full, y1_train_full), (X1_test, y1_test) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ9acz1A3o-8",
        "colab_type": "text"
      },
      "source": [
        "Here is an issue I want to discuss. The following is the number 9 from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rkya8ROj31yh",
        "colab_type": "code",
        "outputId": "ce780714-da6a-4cc0-9e85-3db2de74327a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "number = X1_test[12:13]\n",
        "number = number.reshape([28,28])\n",
        "plt.imshow(number)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9918217e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUAFwBzn4WGl",
        "colab_type": "text"
      },
      "source": [
        "The above picture shows us that the number 9 was already rotated such that it is in some of the most natural way. It lacks the variaties of the way to write the numbers also in normal writing and in some extreme cases. As you will see below, this is other way to write number 9 that we may see often in hand writing notes. The number as rotated 60 degree counter clockwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkbn7lgB3UEt",
        "colab_type": "code",
        "outputId": "f081773a-6066-4383-b1e1-f2caac918075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "\n",
        "import skimage\n",
        "import PIL\n",
        "g = X1_test[12:13]\n",
        "g = np.array(g, dtype='uint8')\n",
        "g=g.reshape([28,28])\n",
        "g = skimage.color.gray2rgb(g)\n",
        "g=PIL.Image.fromarray(g)\n",
        "g = g.rotate(60)\n",
        "g = np.array(g, dtype='uint8')\n",
        "plt.imshow(g)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f991093bbe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rha_9aD_5g_x",
        "colab_type": "text"
      },
      "source": [
        "## Is it a big deal?\n",
        "\n",
        "The answer is yes. Below, I will show you what it is. First, I will train the machine with the original dataset but then I will evaluate the model with the new random rotated dateset. Here is the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivZjLT9k6HNs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "e401a220-e7fc-4ba2-aac6-dcd7e377d9df"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0712 17:43:54.799475 140296605013888 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42fD5ZKo6KWB",
        "colab_type": "code",
        "outputId": "d3bd3e08-6d00-4688-8644-c3ea40d62de3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "model.fit(x_train, y_train, epochs=10)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 10s 171us/sample - loss: 0.2174 - acc: 0.9355\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 10s 163us/sample - loss: 0.0981 - acc: 0.9700\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 10s 163us/sample - loss: 0.0699 - acc: 0.9795\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 10s 162us/sample - loss: 0.0521 - acc: 0.9829\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 10s 161us/sample - loss: 0.0423 - acc: 0.9859\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 10s 166us/sample - loss: 0.0361 - acc: 0.9878\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 10s 166us/sample - loss: 0.0320 - acc: 0.9897\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 10s 162us/sample - loss: 0.0266 - acc: 0.9911\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 10s 159us/sample - loss: 0.0230 - acc: 0.9924\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 10s 160us/sample - loss: 0.0231 - acc: 0.9918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9936284ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yjkaDkn6Xlu",
        "colab_type": "text"
      },
      "source": [
        "And we evaluate the model with the x_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI9pbwHe6V8S",
        "colab_type": "code",
        "outputId": "e75db820-73e8-4d09-8111-08c05cc58f2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 65us/sample - loss: 0.0818 - acc: 0.9807\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0817630238593647, 0.9807]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bFdljy26jAx",
        "colab_type": "text"
      },
      "source": [
        "The result is very good, we attain the accuracy upto 98%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArZerSXw6r32",
        "colab_type": "text"
      },
      "source": [
        "Next, we create a new test set where the set was rotated by random angle from -60 to 60 degree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_zyqYdY6qNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import skimage\n",
        "import PIL\n",
        "random.seed(100)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_gen_test = np.ndarray(shape = (len(x_test),28,28))\n",
        "x_gen_test_angle = np.ndarray(shape = (len(x_test)), dtype = 'int8')\n",
        "for index in range(len(x_test)):\n",
        "  ran_num = random.randint(-60,60)\n",
        "  g = x_test[index]\n",
        "  g = np.array(g, dtype='uint8')\n",
        "  g=g.reshape([28,28])\n",
        "  g = skimage.color.gray2rgb(g)\n",
        "  g=PIL.Image.fromarray(g)\n",
        "  g = g.rotate(ran_num)\n",
        "  g = np.array(g, dtype='uint8')\n",
        "  x_gen_test[index] = g[:,:,0]\n",
        "  x_gen_test_angle[index] = ran_num\n",
        "  \n",
        "x_gen = x_gen_test/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEiZOTNR7VlX",
        "colab_type": "text"
      },
      "source": [
        "Let us evaluate the model with our rotated test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwnnE9r57e2d",
        "colab_type": "code",
        "outputId": "fb8879a1-26a6-4834-d8ca-0371b392037c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "model.evaluate(x_gen, y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 61us/sample - loss: 3.0033 - acc: 0.6811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.0033267280578615, 0.6811]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzE7M5mP-qV5",
        "colab_type": "text"
      },
      "source": [
        "# We see that, the accuracy drops to 69%. That is not good at all. So, what happens here. We will discuss more below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHdOzOBe9m3B",
        "colab_type": "text"
      },
      "source": [
        "## Let us train the model with randomly rotated dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3C2ElNl95UH",
        "colab_type": "text"
      },
      "source": [
        "We keep the same model as before, let us call it new_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSPQnbiX9uj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "new_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXlLCYIR-EPP",
        "colab_type": "text"
      },
      "source": [
        "We also create new training data set with random angle between -60 and 60"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-TELwog-OzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import skimage\n",
        "import PIL\n",
        "random.seed(100)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_gen_train = np.ndarray(shape = (len(x_train),28,28))\n",
        "x_gen_train_angle = np.ndarray(shape = (len(x_train)), dtype = 'int8')\n",
        "for index in range(len(x_train)):\n",
        "  ran_num = random.randint(-60,60)\n",
        "  g = x_train[index]\n",
        "  g = np.array(g, dtype='uint8')\n",
        "  g=g.reshape([28,28])\n",
        "  g = skimage.color.gray2rgb(g)\n",
        "  g=PIL.Image.fromarray(g)\n",
        "  g = g.rotate(ran_num)\n",
        "  g = np.array(g, dtype='uint8')\n",
        "  x_gen_train[index] = g[:,:,0]\n",
        "  x_gen_train_angle[index] = ran_num\n",
        "  \n",
        "x_train_new= x_gen_train / 255.0\n",
        "y_train_new = y_train\n",
        "#x_train_new[30000:] = x_train[:30000]\n",
        "#y_train_new[30000:] = y_train[:30000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_407y9d-3zl",
        "colab_type": "code",
        "outputId": "70eb0924-2ff2-4fbf-bf0b-a59496ff678f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "\n",
        "new_model.fit(x_train_new, y_train_new, epochs=10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 10s 159us/sample - loss: 0.4364 - acc: 0.8660\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 9s 155us/sample - loss: 0.2132 - acc: 0.9332\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 9s 154us/sample - loss: 0.1551 - acc: 0.9520\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 9s 153us/sample - loss: 0.1223 - acc: 0.9609\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 9s 153us/sample - loss: 0.0976 - acc: 0.9690\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 9s 154us/sample - loss: 0.0793 - acc: 0.9742\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 9s 154us/sample - loss: 0.0678 - acc: 0.9776\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 9s 153us/sample - loss: 0.0582 - acc: 0.9799\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 9s 158us/sample - loss: 0.0515 - acc: 0.9826\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 9s 157us/sample - loss: 0.0455 - acc: 0.9844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f990ac89d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29WOaQpI_etx",
        "colab_type": "code",
        "outputId": "e757d262-3b7b-4f46-b53a-95c854ca73d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "x_gen = x_gen_test/255\n",
        "new_model.evaluate(x_gen, y_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 62us/sample - loss: 0.1712 - acc: 0.9551\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1712171384229092, 0.9551]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b9UMD3gBvbp",
        "colab_type": "code",
        "outputId": "d07857b7-335f-488a-cccc-d607ef94368c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "x_gen = x_gen_test/255\n",
        "model.evaluate(x_gen, y_test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 60us/sample - loss: 3.0033 - acc: 0.6811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.0033267280578615, 0.6811]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdRcAzdMB048",
        "colab_type": "text"
      },
      "source": [
        "The new_model gives us the accurary for the rotated test set upto 95%.  And the old model has accuracy about 69%  with the same rotated test set which is much lower than the new_model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CZG39a6Lzf3",
        "colab_type": "text"
      },
      "source": [
        "Then you may ask, what if we test on the original test set. Which model is better in this case. As you see below, we get 96% accuracy for the new_model but we got 98% accuracy for the old model with original training set. However, the difference is not much and it may be the cause of overfitting for the original dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mDk5KzpAHEd",
        "colab_type": "code",
        "outputId": "9b748c03-4c2a-4678-a1a6-33284f1f3377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "new_model.evaluate(x_test, y_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 55us/sample - loss: 31.8734 - acc: 0.9620\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[31.873412122806908, 0.962]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhUN_oALM9Yn",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "With the original dataset, we may overfit the training since some of the number was allign in the most \"vertical\" way. It lack the varieties to train the model to learn different situations which actually occurs in real life. By rotating the images, we train the model to understand different situations for the same things, and therefore, the model learn better and be able to classifies more accurate than the classical way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw1Mm5eAOnnC",
        "colab_type": "text"
      },
      "source": [
        "# Appendix about the code in Google Colab\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4iKQeXkPLd5",
        "colab_type": "text"
      },
      "source": [
        "### Issue 1: \n",
        "\n",
        "I had a problem when I tried to show an image in Google Colab. After searching over internet (I forgot the sources), I made it works by including the following codes\n",
        "\n",
        "\n",
        "import plotly.offline as pyo\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import iplot\n",
        "\n",
        "import cufflinks as cf\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \n",
        "\n",
        "### Issue 2: \n",
        "\n",
        "In the note, I said that we rotate the image. That means you must do it from the image, not from the np.array. If you rotate the np.mdarray, you may not have the same pictures since some part of the pictures can be transformed to different color. That means we may have some bizarre image. \n",
        "\n",
        "So, since the mist set from kerass was saved in np.mdarray, I must convert to the image by using \n",
        "\n",
        "PIL.Image.fromarray()\n",
        "\n",
        "which is from PIL library. Then we use rotate to rotate the image and then we transform back to np.mdarray and reshape the array to [28,28] dimension.\n",
        "\n",
        "Probably, there is other easy way to do all but I am lazy to find one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i6Vtm3E9qzl",
        "colab_type": "text"
      },
      "source": [
        "## More discussion\n",
        "\n",
        "In this part, we want to discuss about using less sample size to train our model by using just a half of observations from MNIST dataset, i.e., we only need 30,000 out of 60,000 observations. We believe that, we still have the same or at least very close accuracy compairing to using the full original dataset training model. Okay, let us start with the code.\n",
        "\n",
        "We still keep the same rotated train set we did before, but we only use the first 30,000 observations to train our model. Since we use less data, it is better to increase the epoch from 10 to 30 to get better training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3QOfpV6BoRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "halfsize_new_model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "halfsize_new_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtoB_JsI-oCn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e8b35f73-fe90-4386-a78e-8848508fd7cb"
      },
      "source": [
        "x_train_new= x_gen_train / 255.0\n",
        "y_train_new = y_train\n",
        "x_train_new[30000:] = x_train[:30000]\n",
        "y_train_new[30000:] = y_train[:30000]\n",
        "halfsize_new_model.fit(x_train_new, y_train_new, epochs=50)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 9s 156us/sample - loss: 3.2810 - acc: 0.7344\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 9s 155us/sample - loss: 1.1753 - acc: 0.7949\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 9s 154us/sample - loss: 1.0460 - acc: 0.8231\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 9s 154us/sample - loss: 0.8726 - acc: 0.8435\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 9s 153us/sample - loss: 0.8308 - acc: 0.8538\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 9s 157us/sample - loss: 0.8292 - acc: 0.8645\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 9s 155us/sample - loss: 0.7829 - acc: 0.8745\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 9s 151us/sample - loss: 0.7598 - acc: 0.8843\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 9s 153us/sample - loss: 0.7367 - acc: 0.8945\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 13s 210us/sample - loss: 0.6836 - acc: 0.9031\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 16s 262us/sample - loss: 0.6975 - acc: 0.9032\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 15s 251us/sample - loss: 0.6829 - acc: 0.9112\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 15s 244us/sample - loss: 0.7520 - acc: 0.9122\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 14s 242us/sample - loss: 0.6581 - acc: 0.9167\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 15s 248us/sample - loss: 0.6281 - acc: 0.9217\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 15s 242us/sample - loss: 0.5799 - acc: 0.9248\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 14s 242us/sample - loss: 0.6281 - acc: 0.9266\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 15s 242us/sample - loss: 0.5719 - acc: 0.9263\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 15s 244us/sample - loss: 0.5454 - acc: 0.9303\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 14s 241us/sample - loss: 0.5698 - acc: 0.9353\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 15s 242us/sample - loss: 0.6190 - acc: 0.9344\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 15s 242us/sample - loss: 0.4968 - acc: 0.9367\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 14s 241us/sample - loss: 0.6575 - acc: 0.9365\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 14s 239us/sample - loss: 0.5405 - acc: 0.9378\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 14s 238us/sample - loss: 0.5061 - acc: 0.9378\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 14s 238us/sample - loss: 0.4601 - acc: 0.9393\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 15s 245us/sample - loss: 0.5935 - acc: 0.9422\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 16s 273us/sample - loss: 0.5589 - acc: 0.9441\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 15s 254us/sample - loss: 0.5892 - acc: 0.9452\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 15s 258us/sample - loss: 0.5342 - acc: 0.9447\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 16s 260us/sample - loss: 0.5453 - acc: 0.9469\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 16s 267us/sample - loss: 0.5042 - acc: 0.9484\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 16s 259us/sample - loss: 0.5536 - acc: 0.9484\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 15s 256us/sample - loss: 0.5843 - acc: 0.9512\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 16s 261us/sample - loss: 0.4834 - acc: 0.9503\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 15s 257us/sample - loss: 0.5214 - acc: 0.9519\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 15s 255us/sample - loss: 0.6192 - acc: 0.9532\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 15s 247us/sample - loss: 0.5434 - acc: 0.9538\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 15s 245us/sample - loss: 0.4889 - acc: 0.9546\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 15s 246us/sample - loss: 0.6193 - acc: 0.9543\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 15s 246us/sample - loss: 0.5012 - acc: 0.9564\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 15s 244us/sample - loss: 0.4582 - acc: 0.9572\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 15s 247us/sample - loss: 0.5304 - acc: 0.9559\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 15s 245us/sample - loss: 0.4037 - acc: 0.9595\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 9s 149us/sample - loss: 0.5106 - acc: 0.9568\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 9s 142us/sample - loss: 0.4872 - acc: 0.9577\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 9s 145us/sample - loss: 0.5383 - acc: 0.9593\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 9s 144us/sample - loss: 0.5133 - acc: 0.9568\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 9s 147us/sample - loss: 0.6375 - acc: 0.9582\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 9s 145us/sample - loss: 0.5206 - acc: 0.9565\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f990aaa81d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhSOIhUg_mD3",
        "colab_type": "text"
      },
      "source": [
        "Next, we test on two cases. First case is for the original x_test and y_test and the other is the x_gen_test and y_test to see how good the training is.\n",
        "\n",
        "The following is for the original x_test, y_test evaluation of our model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWJFoB3X_lGv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "899f6603-5a4d-468c-e464-35a58ff1cf81"
      },
      "source": [
        "halfsize_new_model.evaluate(x_test, y_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 69us/sample - loss: 5.2752 - acc: 0.9484\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.275166777122513, 0.9484]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oP4BRC_D8_R",
        "colab_type": "text"
      },
      "source": [
        "So, we see that we only get 6 points for error compairing to 4 points for error in the full dataset training which is still good enough"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYoSHtJ5AC1q",
        "colab_type": "text"
      },
      "source": [
        "And for the x_gen_new, y_gen_new"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTSU6s15AIu9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d98b0ff5-14f4-40b5-9832-358ebf7e5777"
      },
      "source": [
        "halfsize_new_model.evaluate(x_gen, y_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 83us/sample - loss: 0.3667 - acc: 0.9320\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.36667180723417553, 0.932]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErkuTSNdF7mC",
        "colab_type": "text"
      },
      "source": [
        "It is not well as the model with rotation with the full data by 3 points but it is still good. If we increasing the epoch number to a larger one we may have better accuracy on the x_gen, y_test but it may be overfitting and it could reduce the ability of the model to recognize new factor."
      ]
    }
  ]
}